{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hadoop: Writing and Reading Data with HDFS\n",
    "\n",
    "This notebook demonstrates how to interact with Hadoop's Distributed File System (HDFS) using Python. We will cover the fundamental operations of writing data to HDFS and reading data from HDFS.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Install python packages\n",
    "\n",
    "After selecting the appropriate kernel and creating a Python virtual environment (e.g., named .venv), install the following packages:\n",
    "\n",
    "`hdfs` – A Python library used for interacting with the Hadoop Distributed File System (HDFS). It provides functionality to connect to HDFS clusters, read and write files, and manage HDFS directories.\n",
    "\n",
    "`pandas` – A popular Python library for data manipulation and analysis. It provides powerful data structures like DataFrame and a wide range of functions to work with structured data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install hdfs pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Connect to HDFS\n",
    "\n",
    "Check connectivity to the HDFS system and create a client object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hdfs import InsecureClient\n",
    "try:\n",
    "    client = InsecureClient('http://namenode:9870', user='root')\n",
    "    print(\"Connected!\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Check HDFS folders and files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = client.list('/')\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Download and save the sample data file to your local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
    "urllib.request.urlretrieve(url,'sample_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Copy the file to the HDFS\n",
    "\n",
    "Check on browser [localhost:9870](http://localhost:9870/explorer.html#/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.upload(hdfs_path='data.csv', local_path='sample_data.csv', overwrite=True, permission=775)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Read data from HDFS\n",
    "\n",
    "Read data from HDFS into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "with client.read(hdfs_path='/user/root/data.csv', encoding='utf8') as file:\n",
    "  df = pd.read_csv(file)\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
